# Cognitive Distillation â€“ detecting backdoor attacks on deep models

Result replication of the following paper: [Distilling cognitive backdoor patterns within an image](https://openreview.net/pdf?id=S3D9NLzjnQ5).

The idea is to extract a minimal necessary part of the picture responsible for the model's prediction, and make conclusions about backdoor trigger patterns accordingly.
